{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5V+kfrKnGaeOsC8AYDHHt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiguelAngel9604/spark_exercice_1/blob/main/Pyspark_Exercise_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning Dates and Colum's names**"
      ],
      "metadata": {
        "id": "prPUB9fA9Oc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZZp-8MEw33y"
      },
      "outputs": [],
      "source": [
        "# Pyspark\n",
        "!pip install pyspark\n",
        "# Pyspark stubs\n",
        "!pip install pyspark-stubs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import StringType, IntegerType\n",
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark import SparkConf\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local\") \\\n",
        "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
        "    .config(\"spark.executor.memory\", \"500mb\") \\\n",
        "    .appName(\"Exercise2\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "N1nfU4AixEU4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"/content/Data exercise 2 - Hoja 1 (2).csv\")\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUpv_Ub7yDpd",
        "outputId": "d92f9967-91e3-4b29-b7f9-19c9732df948"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "|it's my name| birth/dob.|\n",
            "+------------+-----------+\n",
            "|       angel| 03-09-2020|\n",
            "|      miguel| 03-08-2021|\n",
            "|        jose|02-Aug-2022|\n",
            "|        raul|29March2022|\n",
            "|       pedro|Mar/2020/22|\n",
            "+------------+-----------+\n",
            "\n",
            "root\n",
            " |-- it's my name: string (nullable = true)\n",
            " |-- birth/dob.: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean data colums names\n",
        "import re\n",
        "cols = [re.sub('[^a-zA-Z0-9]','',c) for c in df.columns]\n",
        "print(cols)\n",
        "#Create new data frame within the new column's names\n",
        "new_df = df.toDF(*cols)\n",
        "new_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH3LVQJHy-dw",
        "outputId": "e35342f0-236d-4beb-9faa-3aec44dc67cf"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsmyname', 'birthdob']\n",
            "+---------+-----------+\n",
            "|itsmyname|   birthdob|\n",
            "+---------+-----------+\n",
            "|    angel| 03-09-2020|\n",
            "|   miguel| 03-08-2021|\n",
            "|     jose|02-Aug-2022|\n",
            "|     raul|29March2022|\n",
            "|    pedro|Mar/2020/22|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create function that will return a new date \n",
        "#This function will return the first columns that is not null using the coalesce, will iterathe over the array of strings and verify the date format\n",
        "def dynamic_date(col,frmts=(\"yyyy-MM-dd\",\"dd-MMM-yyyy\",\"ddMMMMyyyy\",\"MM-dd-yyyy\",\"MMM/yyyy/dd\",\"dd-M-yy\")):\n",
        "\n",
        "  return coalesce(*[to_date(col,i) for i in frmts])\n",
        "\n",
        "res = new_df.withColumn(\"birth_new\",dynamic_date(col(\"birthdob\")))  \n",
        "res.show()\n",
        "#res.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIGB6i5r0Pid",
        "outputId": "df63766e-d7c6-41ce-9016-866ddc28f87d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+----------+\n",
            "|itsmyname|   birthdob| birth_new|\n",
            "+---------+-----------+----------+\n",
            "|    angel| 03-09-2020|2020-03-09|\n",
            "|   miguel| 03-08-2021|2021-03-08|\n",
            "|     jose|02-Aug-2022|2022-08-02|\n",
            "|     raul|29March2022|2022-03-29|\n",
            "|    pedro|Mar/2020/22|2020-03-22|\n",
            "+---------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data process\n",
        "res.createOrReplaceTempView(\"tab\")\n",
        "\n",
        "#result = spark.sql(\"select * from tab where birth_new > '2022-03-07' \")\n",
        "result = spark.sql(\"select * from tab where birth_new >'2021-03-07'\")\n",
        "result.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecbrdRkW1Hy1",
        "outputId": "e0f2102c-ff3b-444d-b153-8d070826bf56"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+----------+\n",
            "|itsmyname|   birthdob| birth_new|\n",
            "+---------+-----------+----------+\n",
            "|   miguel| 03-08-2021|2021-03-08|\n",
            "|     jose|02-Aug-2022|2022-08-02|\n",
            "|     raul|29March2022|2022-03-29|\n",
            "+---------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NcfP_suF9Mg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o_UGgtY19NZR"
      }
    }
  ]
}